name: 'Claude Code Runner - Enhanced'
description: 'Advanced Claude Code CLI with error parsing, context management, metrics collection, and feedback optimization'
author: 'AI Assistant'

inputs:
  task:
    description: 'Task description for Claude'
    required: true
  add-dir:
    description: 'Additional directories to include (comma-separated)'
    required: false
  timeout:
    description: 'Timeout in seconds (default: 300)'
    required: false
    default: '300'
  error-log:
    description: 'Path to error log file for context'
    required: false
  retry-count:
    description: 'Current retry attempt'
    required: false
    default: '0'
  anthropic-api-key:
    description: 'Anthropic API key for Claude Code'
    required: true
  workflow-id:
    description: 'Workflow identifier for metrics tracking'
    required: false
  run-id:
    description: 'Run identifier for metrics tracking'
    required: false
  enable-metrics:
    description: 'Enable performance metrics collection'
    required: false
    default: 'true'
  enable-feedback:
    description: 'Enable feedback loop optimization'
    required: false
    default: 'true'
  max-context-items:
    description: 'Maximum context items to include'
    required: false
    default: '20'
  max-context-tokens:
    description: 'Maximum context tokens'
    required: false
    default: '150000'

outputs:
  success:
    description: 'Whether the execution was successful'
  results:
    description: 'Results from Claude Code CLI'
  error:
    description: 'Error message if execution failed'
  metrics-summary:
    description: 'Performance metrics summary'
  feedback-id:
    description: 'Feedback item ID for tracking'
  retry-recommended:
    description: 'Whether retry is recommended based on error analysis'

runs:
  using: 'composite'
  steps:
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      shell: bash
      run: |
        python -m pip install --upgrade pip
        python -m pip install psutil

    - name: Initialize metrics collection
      shell: bash
      if: inputs.enable-metrics == 'true'
      run: |
        # Create cache directories
        mkdir -p .github/cache/metrics .github/cache/context .github/cache/errors .github/cache/feedback

        # Start metrics tracking
        python .github/actions/claude-code-runner/scripts/metrics_collector.py \
          --project-root . \
          --start-tracking \
          --workflow-id "${{ inputs.workflow-id || github.workflow }}" \
          --run-id "${{ inputs.run-id || github.run_id }}" > .github/cache/current_metrics.json

    - name: Build optimized context
      shell: bash
      run: |
        # Build context with caching and compression
        python .github/actions/claude-code-runner/scripts/context_manager.py \
          --project-root . \
          --max-items ${{ inputs.max-context-items }} \
          --max-tokens ${{ inputs.max-context-tokens }} \
          --output .github/cache/optimized_context.txt

    - name: Parse and analyze errors (if any)
      shell: bash
      if: inputs.error-log != ''
      run: |
        if [ -f "${{ inputs.error-log }}" ]; then
          # Parse errors and determine retry strategy
          python .github/actions/claude-code-runner/scripts/error_parser.py \
            "${{ inputs.error-log }}" \
            --retry-attempt ${{ inputs.retry-count }} \
            > .github/cache/error_analysis.json
        fi

    - name: Run Claude Code with enhanced features
      shell: bash
      env:
        ANTHROPIC_API_KEY: ${{ inputs.anthropic-api-key }}
        CLAUDE_CODE_DISABLE_NONESSENTIAL_TRAFFIC: true
        BASH_DEFAULT_TIMEOUT_MS: ${{ inputs.timeout }}000
      run: |
        # Prepare arguments
        ARGS="--task '${{ inputs.task }}'"
        ARGS="$ARGS --timeout ${{ inputs.timeout }}"
        ARGS="$ARGS --retry-count ${{ inputs.retry-count }}"

        # Add optimized context
        if [ -f ".github/cache/optimized_context.txt" ]; then
          CONTEXT_CONTENT=$(cat .github/cache/optimized_context.txt)
          ARGS="$ARGS --context '${CONTEXT_CONTENT}'"
        fi

        if [ -n "${{ inputs.add-dir }}" ]; then
          IFS=',' read -ra DIRS <<< "${{ inputs.add-dir }}"
          for dir in "${DIRS[@]}"; do
            ARGS="$ARGS --add-dir '$dir'"
          done
        fi

        if [ -n "${{ inputs.error-log }}" ] && [ -f "${{ inputs.error-log }}" ]; then
          ARGS="$ARGS --error-log '${{ inputs.error-log }}'"
        fi

        # Run the script and capture output
        OUTPUT=$(python .github/actions/claude-code-runner/scripts/run_claude_code.py $ARGS)
        EXIT_CODE=$?

        # Save output for analysis
        echo "$OUTPUT" > .github/cache/claude_output.json

        # Set outputs
        if [ $EXIT_CODE -eq 0 ]; then
          echo "success=true" >> $GITHUB_OUTPUT
          echo "results<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        else
          echo "success=false" >> $GITHUB_OUTPUT
          echo "error<<EOF" >> $GITHUB_OUTPUT
          echo "$OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        fi

        # Exit with the same code as the script
        exit $EXIT_CODE

    - name: Analyze execution and collect metrics
      shell: bash
      if: always()
      run: |
        # Generate metrics summary
        if [ "${{ inputs.enable-metrics }}" == "true" ] && [ -f ".github/cache/current_metrics.json" ]; then
          python .github/actions/claude-code-runner/scripts/metrics_collector.py \
            --project-root . \
            --report \
            --days 1 > .github/cache/metrics_report.json

          # Extract key metrics for output
          METRICS_SUMMARY=$(cat .github/cache/metrics_report.json | jq -c '.metrics_summary // {}')
          echo "metrics-summary=$METRICS_SUMMARY" >> $GITHUB_OUTPUT
        fi

        # Analyze error output for retry recommendations
        if [ -f ".github/cache/error_analysis.json" ]; then
          RETRY_RECOMMENDED=$(cat .github/cache/error_analysis.json | jq -r '.should_retry // false')
          echo "retry-recommended=$RETRY_RECOMMENDED" >> $GITHUB_OUTPUT
        fi

    - name: Collect feedback
      shell: bash
      if: always() && inputs.enable-feedback == 'true'
      run: |
        # Determine feedback type based on results
        if [ "${{ job.status }}" == "success" ]; then
          FEEDBACK_TYPE="success"
          SEVERITY="0.1"
        elif [ -f ".github/cache/error_analysis.json" ]; then
          FEEDBACK_TYPE="error"
          SEVERITY="0.8"
        else
          FEEDBACK_TYPE="warning"
          SEVERITY="0.5"
        fi

        # Extract error message if available
        ERROR_MSG=""
        if [ -f ".github/cache/claude_output.json" ]; then
          ERROR_MSG=$(cat .github/cache/claude_output.json | jq -r '.error // empty' | head -c 500)
        fi

        if [ -n "$ERROR_MSG" ]; then
          # Add feedback item
          FEEDBACK_ID=$(python .github/actions/claude-code-runner/scripts/feedback_optimizer.py \
            --project-root . \
            --add-feedback "$ERROR_MSG" \
            --type "$FEEDBACK_TYPE" \
            --source "ci_pipeline" \
            --severity "$SEVERITY" \
            --context '{"workflow": "${{ github.workflow }}", "run_id": "${{ github.run_id }}"}' \
            2>/dev/null | jq -r '.id // empty')

          if [ -n "$FEEDBACK_ID" ]; then
            echo "feedback-id=$FEEDBACK_ID" >> $GITHUB_OUTPUT
          fi
        fi

    - name: Generate optimization report
      shell: bash
      if: inputs.enable-feedback == 'true'
      run: |
        # Generate comprehensive feedback report
        python .github/actions/claude-code-runner/scripts/feedback_optimizer.py \
          --project-root . \
          --report > .github/cache/optimization_report.json 2>/dev/null || true

        # Log insights for visibility
        if [ -f ".github/cache/optimization_report.json" ]; then
          echo "## ðŸ“Š Optimization Insights" >> $GITHUB_STEP_SUMMARY
          INSIGHTS=$(cat .github/cache/optimization_report.json | jq -r '.insights[]? // empty' | head -5)
          if [ -n "$INSIGHTS" ]; then
            echo "$INSIGHTS" | while read insight; do
              echo "- $insight" >> $GITHUB_STEP_SUMMARY
            done
          fi
        fi

    - name: Cleanup and optimization
      shell: bash
      if: always()
      run: |
        # Cleanup old cache data
        python .github/actions/claude-code-runner/scripts/context_manager.py \
          --project-root . \
          --cleanup >/dev/null 2>&1 || true

        python .github/actions/claude-code-runner/scripts/metrics_collector.py \
          --project-root . \
          --cleanup --days 30 >/dev/null 2>&1 || true

        python .github/actions/claude-code-runner/scripts/feedback_optimizer.py \
          --project-root . \
          --cleanup >/dev/null 2>&1 || true

        # Cache directory info
        echo "## ðŸ“ Cache Statistics" >> $GITHUB_STEP_SUMMARY
        echo "- Context cache: $(find .github/cache/context -name "*.cache" 2>/dev/null | wc -l) items" >> $GITHUB_STEP_SUMMARY
        echo "- Metrics records: $(cat .github/cache/metrics.db 2>/dev/null | wc -l) lines" >> $GITHUB_STEP_SUMMARY
        echo "- Feedback items: $(sqlite3 .github/cache/feedback.db 2>/dev/null "SELECT COUNT(*) FROM feedback_items;" 2>/dev/null || echo "0")" >> $GITHUB_STEP_SUMMARY